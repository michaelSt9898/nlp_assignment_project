{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac OS, runs faster on CPU. Possibly beacuse of the small batch size and the subsequent non parallelization of the GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_iterator():\n",
    "    data_dir = Path('dependency_treebank')\n",
    "    for data_file in filter(lambda f: os.path.isfile(data_dir/f) and f.endswith('.dp'), os.listdir(data_dir)):\n",
    "        yield data_dir/data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "\n",
    "train_split = 100\n",
    "val_split = 150\n",
    "\n",
    "file_counter = 0\n",
    "for file in file_iterator():\n",
    "    file_counter += 1\n",
    "    if file_counter <= train_split:\n",
    "        train_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "    elif file_counter <= val_split:\n",
    "        val_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "    else:\n",
    "        test_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "\n",
    "assert len(train_set) == 100\n",
    "assert len(val_set) == 50\n",
    "assert len(test_set) == 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame = pd.concat(train_set)\n",
    "test_frame = pd.concat(test_set)\n",
    "val_frame = pd.concat(val_set)\n",
    "\n",
    "assert sum([e.shape[0] for e in train_set]) == train_frame.shape[0]\n",
    "assert sum([e.shape[0] for e in test_set]) == test_frame.shape[0]\n",
    "assert sum([e.shape[0] for e in val_set]) == val_frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Tokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_frame['token'].values)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoded_doc = tokenizer.texts_to_sequences(train_frame['token'].values)\n",
    "\n",
    "# Not necessary since we encode words and not sentences \n",
    "max_length = 1\n",
    "padded_docs = pad_sequences(encoded_doc, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Vocab ratners\n",
      "Not in Vocab crocidolite\n",
      "Not in Vocab weisfield\n",
      "Not in Vocab veraldi\n",
      "Not in Vocab moleculon\n",
      "Not in Vocab nipponese\n",
      "Not in Vocab nagymaros\n",
      "Not in Vocab ntg\n",
      "Not in Vocab severable\n",
      "Not in Vocab synergistics\n",
      "Not in Vocab kalipharma\n",
      "Not in Vocab tiphook\n",
      "Not in Vocab erbamont\n",
      "Not in Vocab nekoosa\n",
      "Not in Vocab hallwood\n",
      "Not in Vocab vitulli\n",
      "Not in Vocab unicorp\n",
      "Not in Vocab besuboru\n",
      "Not in Vocab pramual\n",
      "Not in Vocab twindam\n",
      "Not in Vocab sidak\n",
      "Not in Vocab micronite\n",
      "Not in Vocab amphobiles\n",
      "Not in Vocab pathlogy\n",
      "Not in Vocab colorliner\n",
      "Not in Vocab potables\n",
      "Not in Vocab scypher\n",
      "Not in Vocab mutchin\n",
      "Not in Vocab akerfeldt\n",
      "Not in Vocab gingl\n",
      "Not in Vocab hasbrouk\n",
      "Not in Vocab txo\n",
      "Not in Vocab chemplus\n",
      "Not in Vocab polyproplene\n",
      "Not in Vocab bumkins\n",
      "Not in Vocab purepac\n",
      "Not in Vocab chinchon\n",
      "Not in Vocab unenticing\n",
      "Not in Vocab derchin\n",
      "Not in Vocab phacoflex\n",
      "Not in Vocab foldability\n",
      "Not in Vocab satrum\n",
      "Not in Vocab waymar\n",
      "Not in Vocab purhasing\n",
      "Not in Vocab ednie\n",
      "Not in Vocab 29year\n",
      "Not in Vocab anku\n",
      "Not in Vocab drobnick\n",
      "Not in Vocab 8415\n",
      "Not in Vocab 35564\n",
      "Not in Vocab 35500\n",
      "Not in Vocab 2691\n",
      "Not in Vocab 3648\n",
      "Not in Vocab continuingly\n",
      "Not in Vocab shokubai\n",
      "Not in Vocab 2163\n",
      "Not in Vocab minicrash\n",
      "Not in Vocab boogieman\n",
      "Not in Vocab propagandizes\n",
      "Not in Vocab macheski\n",
      "Not in Vocab wfrr\n",
      "Not in Vocab ghkm\n",
      "Not in Vocab centerbank\n",
      "Not in Vocab nesb\n",
      "Not in Vocab pennview\n",
      "Not in Vocab univest\n",
      "Not in Vocab yoshihashi\n",
      "Not in Vocab midwesco\n",
      "Not in Vocab nylev\n",
      "Not in Vocab 3436\n",
      "Not in Vocab 0085\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "# use 0 embedding as placeholder\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\telse:\n",
    "\t\tprint(\"Not in Vocab\", word)\n",
    "\t#TODO: Add edgecase OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode train_frame['pos'].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_frame['pos'].values)\n",
    "encoded_Y = encoder.transform(train_frame['pos'].values)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "labels = np_utils.to_categorical(encoded_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 100)            632700    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              234496    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 44)                11308     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 878,504\n",
      "Trainable params: 245,804\n",
      "Non-trainable params: 632,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:20:22.493942: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413/1413 [==============================] - 4s 2ms/step - loss: 0.9973 - accuracy: 0.7230\n",
      "Epoch 2/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.5854 - accuracy: 0.8113\n",
      "Epoch 3/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.5102 - accuracy: 0.8298\n",
      "Epoch 4/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4713 - accuracy: 0.8374\n",
      "Epoch 5/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4448 - accuracy: 0.8421\n",
      "Epoch 6/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4298 - accuracy: 0.8459\n",
      "Epoch 7/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4168 - accuracy: 0.8462\n",
      "Epoch 8/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4069 - accuracy: 0.8508\n",
      "Epoch 9/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8510\n",
      "Epoch 10/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8512\n",
      "Epoch 11/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3880 - accuracy: 0.8535\n",
      "Epoch 12/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8541\n",
      "Epoch 13/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3809 - accuracy: 0.8542\n",
      "Epoch 14/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8534\n",
      "Epoch 15/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3739 - accuracy: 0.8555\n",
      "Epoch 16/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3725 - accuracy: 0.8563\n",
      "Epoch 17/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8550\n",
      "Epoch 18/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3684 - accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8557\n",
      "Epoch 20/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8562\n",
      "Epoch 21/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3644 - accuracy: 0.8562\n",
      "Epoch 22/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3630 - accuracy: 0.8567\n",
      "Epoch 23/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8581\n",
      "Epoch 24/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3616 - accuracy: 0.8567\n",
      "Epoch 25/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8570\n",
      "Epoch 26/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.8569\n",
      "Epoch 27/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3593 - accuracy: 0.8577\n",
      "Epoch 28/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3588 - accuracy: 0.8571\n",
      "Epoch 29/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3583 - accuracy: 0.8563\n",
      "Epoch 30/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3574 - accuracy: 0.8585\n",
      "Epoch 31/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3576 - accuracy: 0.8572\n",
      "Epoch 32/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3556 - accuracy: 0.8565\n",
      "Epoch 33/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3554 - accuracy: 0.8573\n",
      "Epoch 34/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3555 - accuracy: 0.8560\n",
      "Epoch 35/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3547 - accuracy: 0.8575\n",
      "Epoch 36/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3544 - accuracy: 0.8578\n",
      "Epoch 37/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3542 - accuracy: 0.8574\n",
      "Epoch 38/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3538 - accuracy: 0.8573\n",
      "Epoch 40/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3526 - accuracy: 0.8576\n",
      "Epoch 41/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3528 - accuracy: 0.8571\n",
      "Epoch 42/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3514 - accuracy: 0.8580\n",
      "Epoch 43/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3524 - accuracy: 0.8573\n",
      "Epoch 44/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3520 - accuracy: 0.8581\n",
      "Epoch 45/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3518 - accuracy: 0.8579\n",
      "Epoch 46/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3506 - accuracy: 0.8570\n",
      "Epoch 47/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8581\n",
      "Epoch 48/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3507 - accuracy: 0.8574\n",
      "Epoch 49/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3500 - accuracy: 0.8585\n",
      "Epoch 50/50\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8585\n",
      "1413/1413 [==============================] - 1s 726us/step - loss: 0.3379 - accuracy: 0.8631\n",
      "Accuracy: 86.305612\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1, trainable=False)\n",
    "model.add(e)\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128), input_shape=(None, 50)))\n",
    "model.add(Dense(44, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1, 100)            632700    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 512)              549888    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 44)                22572     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,205,160\n",
      "Trainable params: 572,460\n",
      "Non-trainable params: 632,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1413/1413 [==============================] - 5s 2ms/step - loss: 0.8852 - accuracy: 0.7417\n",
      "Epoch 2/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.5811 - accuracy: 0.8107\n",
      "Epoch 3/50\n",
      "1413/1413 [==============================] - 4s 2ms/step - loss: 0.5130 - accuracy: 0.8256\n",
      "Epoch 4/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4749 - accuracy: 0.8345\n",
      "Epoch 5/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4498 - accuracy: 0.8389\n",
      "Epoch 6/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4338 - accuracy: 0.8425\n",
      "Epoch 7/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4200 - accuracy: 0.8453\n",
      "Epoch 8/50\n",
      "1413/1413 [==============================] - 4s 2ms/step - loss: 0.4093 - accuracy: 0.8469\n",
      "Epoch 9/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.4015 - accuracy: 0.8488\n",
      "Epoch 10/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3946 - accuracy: 0.8494\n",
      "Epoch 11/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3883 - accuracy: 0.8506\n",
      "Epoch 12/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3844 - accuracy: 0.8524\n",
      "Epoch 13/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3806 - accuracy: 0.8523\n",
      "Epoch 14/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3780 - accuracy: 0.8534\n",
      "Epoch 15/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3751 - accuracy: 0.8526\n",
      "Epoch 16/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3730 - accuracy: 0.8540\n",
      "Epoch 17/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3711 - accuracy: 0.8549\n",
      "Epoch 18/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3693 - accuracy: 0.8546\n",
      "Epoch 19/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3678 - accuracy: 0.8552\n",
      "Epoch 20/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3661 - accuracy: 0.8551\n",
      "Epoch 21/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3643 - accuracy: 0.8562\n",
      "Epoch 22/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3642 - accuracy: 0.8565\n",
      "Epoch 23/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3629 - accuracy: 0.8553\n",
      "Epoch 24/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3622 - accuracy: 0.8562\n",
      "Epoch 25/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3612 - accuracy: 0.8560\n",
      "Epoch 26/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3602 - accuracy: 0.8575\n",
      "Epoch 27/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3601 - accuracy: 0.8566\n",
      "Epoch 28/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3581 - accuracy: 0.8569\n",
      "Epoch 29/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3590 - accuracy: 0.8579\n",
      "Epoch 30/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3575 - accuracy: 0.8570\n",
      "Epoch 31/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3578 - accuracy: 0.8564\n",
      "Epoch 32/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3562 - accuracy: 0.8576\n",
      "Epoch 33/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3567 - accuracy: 0.8573\n",
      "Epoch 34/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3561 - accuracy: 0.8576\n",
      "Epoch 35/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3547 - accuracy: 0.8584\n",
      "Epoch 36/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3547 - accuracy: 0.8574\n",
      "Epoch 37/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3546 - accuracy: 0.8569\n",
      "Epoch 38/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3536 - accuracy: 0.8584\n",
      "Epoch 39/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3539 - accuracy: 0.8565\n",
      "Epoch 40/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8580\n",
      "Epoch 41/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3535 - accuracy: 0.8574\n",
      "Epoch 42/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8584\n",
      "Epoch 43/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3518 - accuracy: 0.8577\n",
      "Epoch 44/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3522 - accuracy: 0.8573\n",
      "Epoch 45/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3514 - accuracy: 0.8575\n",
      "Epoch 46/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3512 - accuracy: 0.8571\n",
      "Epoch 47/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3508 - accuracy: 0.8580\n",
      "Epoch 48/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3506 - accuracy: 0.8579\n",
      "Epoch 49/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3502 - accuracy: 0.8573\n",
      "Epoch 50/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3498 - accuracy: 0.8592\n",
      "1413/1413 [==============================] - 2s 932us/step - loss: 0.3373 - accuracy: 0.8560\n",
      "Accuracy: 85.595453\n"
     ]
    }
   ],
   "source": [
    "# Using GRU instead of LSTM\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1, trainable=False)\n",
    "model.add(e)\n",
    "# A\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=128), input_shape=(None, 50)))\n",
    "model.add(Dense(44, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 1, 100)            632700    \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 1, 256)           234496    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 44)                5676      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,992\n",
      "Trainable params: 437,292\n",
      "Non-trainable params: 632,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1413/1413 [==============================] - 6s 3ms/step - loss: 0.9629 - accuracy: 0.7225\n",
      "Epoch 2/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.5385 - accuracy: 0.8202\n",
      "Epoch 3/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.4713 - accuracy: 0.8359\n",
      "Epoch 4/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.4409 - accuracy: 0.8414\n",
      "Epoch 5/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.4207 - accuracy: 0.8448\n",
      "Epoch 6/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.4071 - accuracy: 0.8488\n",
      "Epoch 7/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3957 - accuracy: 0.8506\n",
      "Epoch 8/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3881 - accuracy: 0.8528\n",
      "Epoch 9/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3813 - accuracy: 0.8537\n",
      "Epoch 10/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3767 - accuracy: 0.8542\n",
      "Epoch 11/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3726 - accuracy: 0.8547\n",
      "Epoch 12/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3690 - accuracy: 0.8553\n",
      "Epoch 13/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3657 - accuracy: 0.8581\n",
      "Epoch 14/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3638 - accuracy: 0.8568\n",
      "Epoch 15/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3614 - accuracy: 0.8585\n",
      "Epoch 16/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3586 - accuracy: 0.8585\n",
      "Epoch 17/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3569 - accuracy: 0.8585\n",
      "Epoch 18/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3555 - accuracy: 0.8583\n",
      "Epoch 19/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3542 - accuracy: 0.8577\n",
      "Epoch 20/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3527 - accuracy: 0.8590\n",
      "Epoch 21/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3512 - accuracy: 0.8591\n",
      "Epoch 22/50\n",
      "1413/1413 [==============================] - 5s 3ms/step - loss: 0.3509 - accuracy: 0.8589\n",
      "Epoch 23/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3492 - accuracy: 0.8580\n",
      "Epoch 24/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3486 - accuracy: 0.8596\n",
      "Epoch 25/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3477 - accuracy: 0.8592\n",
      "Epoch 26/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3466 - accuracy: 0.8593\n",
      "Epoch 27/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3457 - accuracy: 0.8604\n",
      "Epoch 28/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3458 - accuracy: 0.8590\n",
      "Epoch 29/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3444 - accuracy: 0.8599\n",
      "Epoch 30/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3439 - accuracy: 0.8605\n",
      "Epoch 31/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3435 - accuracy: 0.8611\n",
      "Epoch 32/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3432 - accuracy: 0.8592\n",
      "Epoch 33/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3423 - accuracy: 0.8610\n",
      "Epoch 34/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3420 - accuracy: 0.8601\n",
      "Epoch 35/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3420 - accuracy: 0.8603\n",
      "Epoch 36/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3412 - accuracy: 0.8606\n",
      "Epoch 37/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3407 - accuracy: 0.8606\n",
      "Epoch 38/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3407 - accuracy: 0.8586\n",
      "Epoch 39/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3402 - accuracy: 0.8619\n",
      "Epoch 40/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3401 - accuracy: 0.8610\n",
      "Epoch 41/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3403 - accuracy: 0.8608\n",
      "Epoch 42/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3396 - accuracy: 0.8613\n",
      "Epoch 43/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3394 - accuracy: 0.8604\n",
      "Epoch 44/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3394 - accuracy: 0.8605\n",
      "Epoch 45/50\n",
      "1413/1413 [==============================] - 6s 4ms/step - loss: 0.3386 - accuracy: 0.8616\n",
      "Epoch 46/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3386 - accuracy: 0.8606\n",
      "Epoch 47/50\n",
      "1413/1413 [==============================] - 5s 3ms/step - loss: 0.3385 - accuracy: 0.8621\n",
      "Epoch 48/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3391 - accuracy: 0.8623\n",
      "Epoch 49/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3385 - accuracy: 0.8621\n",
      "Epoch 50/50\n",
      "1413/1413 [==============================] - 4s 3ms/step - loss: 0.3380 - accuracy: 0.8617\n",
      "1413/1413 [==============================] - 2s 1ms/step - loss: 0.3317 - accuracy: 0.8650\n",
      "Accuracy: 86.504722\n"
     ]
    }
   ],
   "source": [
    "# Use additional LSTM layer\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1, trainable=False)\n",
    "model.add(e)\n",
    "# A\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True), input_shape=(None, 50)))\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(Dense(44, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 1, 100)            632700    \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 256)              234496    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 44)                5676      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 905,768\n",
      "Trainable params: 273,068\n",
      "Non-trainable params: 632,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1413/1413 [==============================] - 4s 2ms/step - loss: 0.8624 - accuracy: 0.7429\n",
      "Epoch 2/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.5419 - accuracy: 0.8184\n",
      "Epoch 3/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4848 - accuracy: 0.8306\n",
      "Epoch 4/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4530 - accuracy: 0.8382\n",
      "Epoch 5/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4346 - accuracy: 0.8423\n",
      "Epoch 6/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4210 - accuracy: 0.8444\n",
      "Epoch 7/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4092 - accuracy: 0.8481\n",
      "Epoch 8/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.4019 - accuracy: 0.8497\n",
      "Epoch 9/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3953 - accuracy: 0.8491\n",
      "Epoch 10/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3922 - accuracy: 0.8502\n",
      "Epoch 11/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3874 - accuracy: 0.8511\n",
      "Epoch 12/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3836 - accuracy: 0.8533\n",
      "Epoch 13/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3810 - accuracy: 0.8539\n",
      "Epoch 14/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3807 - accuracy: 0.8537\n",
      "Epoch 15/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3769 - accuracy: 0.8545\n",
      "Epoch 16/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3766 - accuracy: 0.8543\n",
      "Epoch 17/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3742 - accuracy: 0.8547\n",
      "Epoch 18/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3729 - accuracy: 0.8556\n",
      "Epoch 19/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3723 - accuracy: 0.8561\n",
      "Epoch 20/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3697 - accuracy: 0.8555\n",
      "Epoch 21/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3694 - accuracy: 0.8565\n",
      "Epoch 22/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3689 - accuracy: 0.8557\n",
      "Epoch 23/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3677 - accuracy: 0.8556\n",
      "Epoch 24/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3673 - accuracy: 0.8564\n",
      "Epoch 25/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3657 - accuracy: 0.8576\n",
      "Epoch 26/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3656 - accuracy: 0.8572\n",
      "Epoch 27/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3662 - accuracy: 0.8557\n",
      "Epoch 28/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3643 - accuracy: 0.8556\n",
      "Epoch 29/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3645 - accuracy: 0.8546\n",
      "Epoch 30/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3639 - accuracy: 0.8569\n",
      "Epoch 31/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3627 - accuracy: 0.8563\n",
      "Epoch 32/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3622 - accuracy: 0.8567\n",
      "Epoch 33/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3626 - accuracy: 0.8558\n",
      "Epoch 34/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3602 - accuracy: 0.8564\n",
      "Epoch 35/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3608 - accuracy: 0.8558\n",
      "Epoch 36/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3600 - accuracy: 0.8575\n",
      "Epoch 37/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3595 - accuracy: 0.8568\n",
      "Epoch 38/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3597 - accuracy: 0.8577\n",
      "Epoch 39/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3585 - accuracy: 0.8571\n",
      "Epoch 40/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3591 - accuracy: 0.8563\n",
      "Epoch 41/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3574 - accuracy: 0.8570\n",
      "Epoch 42/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3571 - accuracy: 0.8595\n",
      "Epoch 43/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3578 - accuracy: 0.8573\n",
      "Epoch 44/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3576 - accuracy: 0.8581\n",
      "Epoch 45/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3565 - accuracy: 0.8579\n",
      "Epoch 46/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3569 - accuracy: 0.8573\n",
      "Epoch 47/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3558 - accuracy: 0.8579\n",
      "Epoch 48/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3563 - accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3549 - accuracy: 0.8577\n",
      "Epoch 50/50\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3553 - accuracy: 0.8577\n",
      "1413/1413 [==============================] - 2s 731us/step - loss: 0.3399 - accuracy: 0.8555\n",
      "Accuracy: 85.548991\n"
     ]
    }
   ],
   "source": [
    "# Use additional Dense layer\n",
    "from tensorflow import keras\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1, trainable=False)\n",
    "model.add(e)\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128), input_shape=(None, 50)))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(44, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('play')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b727ce1e70db608c3383dbdfc7515fdf59394b92aeb6660adc1fd5fe991747d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

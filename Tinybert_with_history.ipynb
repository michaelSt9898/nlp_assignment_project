{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "M6vEfoSS_god",
      "metadata": {
        "id": "M6vEfoSS_god"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8rFYDAyi_gok",
      "metadata": {
        "id": "8rFYDAyi_gok"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xpq3nDoH_gon",
      "metadata": {
        "id": "xpq3nDoH_gon"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zSPNUDls_goq",
      "metadata": {
        "id": "zSPNUDls_goq"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o1a7H6gC_gos",
      "metadata": {
        "id": "o1a7H6gC_gos"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: an question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BgyOuisN_gou",
      "metadata": {
        "id": "BgyOuisN_gou"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m5MaMicc_gow",
      "metadata": {
        "id": "m5MaMicc_gow"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vfzOVhKq_goy",
      "metadata": {
        "id": "vfzOVhKq_goy"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8iLzifEu_go1",
      "metadata": {
        "id": "8iLzifEu_go1"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C6apwV-Q_go4",
      "metadata": {
        "id": "C6apwV-Q_go4"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X5Tc9HrU_go6",
      "metadata": {
        "id": "X5Tc9HrU_go6"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFPhY21__go8",
      "metadata": {
        "id": "LFPhY21__go8"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lk9pq-xD_go_",
      "metadata": {
        "id": "Lk9pq-xD_go_"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9TcJfEfH_gpB",
      "metadata": {
        "id": "9TcJfEfH_gpB"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r7U-htDoZ8xC",
      "metadata": {
        "id": "r7U-htDoZ8xC"
      },
      "source": [
        "***Unknown is given in the data when it is an unanswerable question***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "R0exckvfp6-p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0exckvfp6-p",
        "outputId": "98a058db-4b31-41b8-e5e1-3eb9607b4f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ktrain in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (0.31.10)\n",
            "Requirement already satisfied: joblib in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.5.1)\n",
            "Requirement already satisfied: syntok>1.3.3 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: requests in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (2.28.1)\n",
            "Requirement already satisfied: packaging in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (21.3)\n",
            "Collecting transformers==4.17.0\n",
            "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: sentencepiece in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (0.1.97)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (0.89.0)\n",
            "Requirement already satisfied: langdetect in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: jieba in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (3.6.2)\n",
            "Requirement already satisfied: chardet in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (5.1.0)\n",
            "Requirement already satisfied: scikit-learn in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (1.1.3)\n",
            "Requirement already satisfied: cchardet in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: whoosh in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (1.23.4)\n",
            "Requirement already satisfied: sacremoses in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (0.11.1)\n",
            "Requirement already satisfied: filelock in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers==4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: keras-transformer==0.40.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
            "Requirement already satisfied: keras-pos-embd==0.13.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-layer-normalization==0.16.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
            "Requirement already satisfied: keras-multi-head==0.29.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
            "Requirement already satisfied: keras-embed-sim==0.10.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (9.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (1.0.6)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (4.38.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from pandas>=1.0.1->ktrain) (2022.6)\n",
            "Requirement already satisfied: six in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->ktrain) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->ktrain) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->ktrain) (2022.9.24)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from scikit-learn->ktrain) (1.9.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0->ktrain) (4.4.0)\n",
            "Requirement already satisfied: click in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from sacremoses->transformers==4.17.0->ktrain) (8.1.3)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.25.1\n",
            "    Uninstalling transformers-4.25.1:\n",
            "      Successfully uninstalled transformers-4.25.1\n",
            "Successfully installed transformers-4.17.0\n",
            "Requirement already satisfied: datasets in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (2.7.1)\n",
            "Requirement already satisfied: pandas in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (1.5.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: xxhash in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: packaging in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (1.23.4)\n",
            "Requirement already satisfied: dill<0.3.7 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: responses<0.19 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: filelock in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (4.17.0)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (1.23.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: filelock in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anani/miniforge3/envs/play/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.17.0\n",
            "    Uninstalling transformers-4.17.0:\n",
            "      Successfully uninstalled transformers-4.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ktrain 0.31.10 requires transformers==4.17.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain\n",
        "!pip install datasets\n",
        "!pip install transformers --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "hcXQLnRPvfKW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcXQLnRPvfKW",
        "outputId": "36e1cbd3-271a-4316-805c-928231b03f9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.25.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Y_mJPNitxpjc",
      "metadata": {
        "id": "Y_mJPNitxpjc"
      },
      "outputs": [],
      "source": [
        "# imports and constants\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset, load_metric\n",
        "import json\n",
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "from transformers import AutoTokenizer, EncoderDecoderModel, TFAutoModelForQuestionAnswering, create_optimizer\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "# from google.colab import drive\n",
        "import collections\n",
        "from datasets import DatasetDict\n",
        "\n",
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "rs = 42\n",
        "set_reproducibility(rs)\n",
        "\n",
        "max_answer_length = 30\n",
        "\n",
        "num_train_epochs = 3\n",
        "batch_size = 128\n",
        "squad_v2 = False\n",
        "\n",
        "max_items_in_set = 5000\n",
        "\n",
        "model_checkpoint = \"prajjwal1/bert-tiny\"#\"distilroberta-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7xoISEc3oYos",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xoISEc3oYos",
        "outputId": "76fc94c1-7791-4dc6-dbdd-bad1183a6ee2"
      },
      "outputs": [],
      "source": [
        "# drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "snSy4P-E_gpD",
      "metadata": {
        "id": "snSy4P-E_gpD"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "iIrQJVDh_gpF",
      "metadata": {
        "id": "iIrQJVDh_gpF"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dJKGLyMU_gpK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJKGLyMU_gpK",
        "outputId": "da96e6d4-4fb3-4800-de3b-329fda2f2036"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "XY1VhHxEP8oo",
      "metadata": {
        "id": "XY1VhHxEP8oo"
      },
      "outputs": [],
      "source": [
        "\n",
        "pathtrain = \"coqa/\" + \"train.json\"\n",
        "pathtest = \"coqa/\" + \"test.json\"\n",
        "\n",
        "with open(pathtrain, \"r\") as train:\n",
        "  train_data = json.load(train)\n",
        "\n",
        "train_data = train_data[\"data\"]\n",
        "\n",
        "with open(pathtest, \"r\") as test:\n",
        "  test_data = json.load(test)\n",
        "\n",
        "test_data = test_data[\"data\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eCtfeIWkPlHK",
      "metadata": {
        "id": "eCtfeIWkPlHK"
      },
      "source": [
        "###Unanswerable QA Pairs are being removed (Task 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "85Er7hKRPhCE",
      "metadata": {
        "id": "85Er7hKRPhCE"
      },
      "outputs": [],
      "source": [
        "def filter_unknowns(data):\n",
        "  \"\"\"This function removes unanswerable QA pairs by only adding the answers that are not \n",
        "     indicated as unknown to the data and then returns that dataset\n",
        "  \"\"\"\n",
        "  for i in range(len(data)):\n",
        "    am_questions = len(data[i]['questions'])\n",
        "\n",
        "    omitted = 0\n",
        "    temp_questions = dict()\n",
        "    temp_answers = dict()\n",
        "\n",
        "    for j in range(am_questions):\n",
        "      if data[i]['answers'][j]['input_text'] != 'unknown':\n",
        "\n",
        "        temp_questions[j - omitted] = data[i]['questions'][j]\n",
        "        temp_answers[j - omitted] = data[i]['answers'][j]\n",
        "      else:\n",
        "        omitted += 1\n",
        "\n",
        "    # assumes that there exist at least one question with an answer per context\n",
        "    data[i]['questions'] = temp_questions\n",
        "    data[i]['answers'] = temp_answers\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "oh730xedYILy",
      "metadata": {
        "id": "oh730xedYILy"
      },
      "outputs": [],
      "source": [
        "train_data = filter_unknowns(train_data)\n",
        "test_data  = filter_unknowns(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cuwpgw5m_gpN",
      "metadata": {
        "id": "cuwpgw5m_gpN"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6P4TA4dw_gpP",
      "metadata": {
        "id": "6P4TA4dw_gpP"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bzth7hyIl4Lt",
      "metadata": {
        "id": "bzth7hyIl4Lt"
      },
      "outputs": [],
      "source": [
        "train, validation = train_test_split(train_data, test_size = 0.2, random_state=rs)\n",
        "test = test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "JPb112L-mOZq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPb112L-mOZq",
        "outputId": "8aed21be-88a2-4a1e-e522-3bb537f5513b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5759\n",
            "1440\n",
            "500\n"
          ]
        }
      ],
      "source": [
        "print(len(train))\n",
        "print(len(validation))\n",
        "print(len(test))\n",
        "#As can be seen the data is split into train data (80%) and validation data (20%)\n",
        "#STILL HAVE TO CHECK THAT A DIALOGUE ONLY APPEARS IN ONE SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "CIIgVtyYO_Pe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIIgVtyYO_Pe",
        "outputId": "2dbd4a95-1d06-4751-9143-26b620f0cd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \n",
            "\n",
            "On Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \n",
            "\n",
            "\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \n",
            "\n",
            "Tunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \n",
            "\n",
            "More than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \n",
            "\n",
            "Voters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \n",
            "\n",
            "\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \n",
            "\n",
            "\"Before we never even had the right to say 'yes' or 'no.'\" \n",
            "\n",
            "Nearby, banker Aid Naghmaichi said she didn't mind the long wait to vote. \n",
            "\n",
            "---\n",
            "\n",
            "0\n",
            "Q: Where is this taking place?\n",
            "A: Tunisia\n",
            "R: Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \n",
            "\n",
            "1\n",
            "Q: What is being voted on?\n",
            "A: Representatives  are being chosen\n",
            "R: \"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi\n",
            "\n",
            "2\n",
            "Q: What day of the week did they vote?\n",
            "A: Sunday\n",
            "R:  Polls closed late Sunday in Tunisia, t\n",
            "\n",
            "3\n",
            "Q: When was the last one held?\n",
            "A: 1956\n",
            "R: some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \n",
            "\n",
            "4\n",
            "Q: What else happened then?\n",
            "A: Country gained its independence\n",
            "R: in the nation's first national elections since the country's independence in 1956.\n",
            "\n",
            "5\n",
            "Q: Where are people voting?\n",
            "A: Menzah neighborhood\n",
            "R: On Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood,\n",
            "\n",
            "6\n",
            "Q: What is something they turned into a place to vote?\n",
            "A: Schools\n",
            "R: On Sunday, long lines of voters snaked around schools-turned-polling-stations\n",
            "\n",
            "7\n",
            "Q: Did anyone have to wait?\n",
            "A: Yes\n",
            "R: some waiting for hours to cast a vote\n",
            "\n",
            "8\n",
            "Q: Who speaks about this?\n",
            "A: Cnn\n",
            "R: TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def fancy_print_dialogue(dialogue):\n",
        "  \"\"\"This function helps the user to see the dialogues in a more clearer view\n",
        "  \"\"\"\n",
        "  print(dialogue['story'])\n",
        "  am_questions = len(dialogue['questions'])\n",
        "\n",
        "  print()\n",
        "  print(\"---\")\n",
        "  print()\n",
        "\n",
        "  for i in range(am_questions):\n",
        "    print(i)\n",
        "    print(\"Q:\", dialogue['questions'][i]['input_text'])\n",
        "    print(\"A:\", dialogue['answers'][i]['input_text'])\n",
        "    print(\"R:\", dialogue['answers'][i]['span_text'])\n",
        "    print()\n",
        "\n",
        "fancy_print_dialogue(train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CgkuS-cLQMC0",
      "metadata": {
        "id": "CgkuS-cLQMC0"
      },
      "source": [
        "# Reformating our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "-g4yzcGQyFM_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g4yzcGQyFM_",
        "outputId": "64631e0f-697e-4369-e187-7097239b5c4f"
      },
      "outputs": [],
      "source": [
        "def get_best_match(query, corpus):\n",
        "  \"\"\"Finding the best match as a string between the query and corpus which in this case\n",
        "     is the answer and the answer in the context. This function returns the index\n",
        "     of the answer in the context.\n",
        "  \"\"\"\n",
        "  best_idx = 0\n",
        "  best_am_mismatches = 0\n",
        "\n",
        "  for j in range((len(query))):\n",
        "    if j >= len(corpus):\n",
        "      break\n",
        "    if query[j] != corpus[j]:\n",
        "      best_am_mismatches += 1\n",
        "\n",
        "  for i in range(len(corpus)-len(query)):\n",
        "    current_am_mismatches = 0\n",
        "    for j in range((len(query))):\n",
        "      if query[j] != corpus[j+i]:\n",
        "        current_am_mismatches += 1\n",
        "        if current_am_mismatches >= best_am_mismatches:\n",
        "          break\n",
        "    if current_am_mismatches <= best_am_mismatches:\n",
        "      best_idx = i\n",
        "      best_am_mismatches = current_am_mismatches\n",
        "    \n",
        "  return best_idx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "CGQnFpoQ9ciK",
      "metadata": {
        "id": "CGQnFpoQ9ciK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['context', 'question', 'answers', 'id', 'source', 'filename', 'name'],\n",
              "        num_rows: 5013\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['context', 'question', 'answers', 'id', 'source', 'filename', 'name'],\n",
              "        num_rows: 5005\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['context', 'question', 'answers', 'id', 'source', 'filename', 'name'],\n",
              "        num_rows: 5003\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gen(data):\n",
        "  \"\"\"In this function the data is generated by giving the index of the answer in the context in the\n",
        "     answer column.  \n",
        "  \"\"\"\n",
        "  count = 0\n",
        "    \n",
        "  for i in range(len(data)):\n",
        "\n",
        "    dialogue = data[i]\n",
        "\n",
        "    am_questions = len(dialogue['questions'])\n",
        "\n",
        "    context = dialogue['story']\n",
        "\n",
        "    for i in range(am_questions):\n",
        "      question_text = dialogue['questions'][i]['input_text']\n",
        "      answer_text = dialogue['answers'][i]['input_text']\n",
        "\n",
        "      #Finding the start of the answer string\n",
        "      span_start = dialogue['answers'][i]['span_start']\n",
        "      span_end = dialogue['answers'][i]['span_end']\n",
        "      R = context[span_start:span_end]\n",
        "      answer_start = get_best_match(answer_text, R) + span_start\n",
        "      \n",
        "      if answer_start == None:\n",
        "        print(question_text)\n",
        "        print(answer_text.lower())\n",
        "        print(context)\n",
        "        print(span_start, span_end)\n",
        "        print(R)\n",
        "        print(answer_start)\n",
        "\n",
        "      assert answer_start != None\n",
        "\n",
        "      answer = (dict({'text':[answer_text], 'answer_start' : [answer_start]}))\n",
        "\n",
        "      yield context, question_text, answer,  dialogue[\"id\"] + str(i), dialogue[\"source\"], dialogue[\"filename\"], dialogue[\"name\"]\n",
        "\n",
        "      context += ' ' + question_text + ' ' + answer_text\n",
        "\n",
        "      count += 1\n",
        "\n",
        "    if count >= max_items_in_set:\n",
        "      break\n",
        "\n",
        "#Using the function gen to generate the datafiles\n",
        "df_train_final = pd.DataFrame(gen(train))\n",
        "df_train_final.rename(columns = {0:'context', 1:'question', 2:'answers', 3:'id',4:'source',5:'filename',6:'name'}, inplace = True)\n",
        "\n",
        "df_validation_final = pd.DataFrame(gen(validation))\n",
        "df_validation_final.rename(columns = {0:'context', 1:'question', 2:'answers', 3:'id',4:'source',5:'filename',6:'name'}, inplace = True)\n",
        "\n",
        "df_test_final = pd.DataFrame(gen(test))\n",
        "df_test_final.rename(columns = {0:'context', 1:'question', 2:'answers', 3:'id',4:'source',5:'filename',6:'name'}, inplace = True)\n",
        "\n",
        "train_dataset      = Dataset.from_pandas(df_train_final)\n",
        "validation_dataset = Dataset.from_pandas(df_validation_final)\n",
        "test_dataset       = Dataset.from_pandas(df_test_final)\n",
        "\n",
        "#Making a dictionary consisting of the train, validation and test set.\n",
        "datasets= DatasetDict({\"train\":train_dataset,\"validation\":validation_dataset,\"test\":test_dataset})\n",
        "datasets.shuffle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bbVvqowhyO-k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbVvqowhyO-k",
        "outputId": "5b5a035a-c994-4756-bae9-fd61a1bdc9d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>filename</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.</td>\n",
              "      <td>Where is this taking place?</td>\n",
              "      <td>{'answer_start': [52], 'text': ['Tunisia']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is0</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.  Where is this taking place? Tunisia</td>\n",
              "      <td>What is being voted on?</td>\n",
              "      <td>{'answer_start': [504], 'text': ['Representatives  are being chosen']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is1</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.  Where is this taking place? Tunisia What is being voted on? Representatives  are being chosen</td>\n",
              "      <td>What day of the week did they vote?</td>\n",
              "      <td>{'answer_start': [42], 'text': ['Sunday']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is2</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.  Where is this taking place? Tunisia What is being voted on? Representatives  are being chosen What day of the week did they vote? Sunday</td>\n",
              "      <td>When was the last one held?</td>\n",
              "      <td>{'answer_start': [427], 'text': ['1956']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is3</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.  Where is this taking place? Tunisia What is being voted on? Representatives  are being chosen What day of the week did they vote? Sunday When was the last one held? 1956</td>\n",
              "      <td>What else happened then?</td>\n",
              "      <td>{'answer_start': [400], 'text': ['Country gained its independence']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is4</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis's upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation's first national elections since the country's independence in 1956. \\n\\n\"It's a wonderful day. It's the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia's election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It's a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say 'yes' or 'no.'\" \\n\\nNearby, banker Aid Naghmaichi said she didn't mind the long wait to vote.  Where is this taking place? Tunisia What is being voted on? Representatives  are being chosen What day of the week did they vote? Sunday When was the last one held? 1956 What else happened then? Country gained its independence</td>\n",
              "      <td>Where are people voting?</td>\n",
              "      <td>{'answer_start': [291], 'text': ['Menzah neighborhood']}</td>\n",
              "      <td>308q0pevb8dq8b7v262io567awb9is5</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "      <td>cnn_21eaf3eb9e3fc5140001e64d95533c88920bb425.story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CHAPTER XXV \\n\\nA CLUE \\n\\nThere was a touch of frost in the still air and the light was fading. A yellow glow lingered in the southwest beyond Criffell's sloping shoulder, which ran up against it, tinged a deep violet. Masses of soft, gray cloud floated above the mountain's summit; but the sky was clear overhead, and a thin new moon grew brighter in the east This was why the murmur of the sea came out of the distance in a muffled roar, for the tides run fast when the moon is young. \\n\\nElsie, walking homeward, vacantly noticed how bright the crescent gleamed above the dusky firs, as she entered the gloom of a straggling wood at the foot of the hill on which Appleyard was built. She had been out all the afternoon and now she shrank from going home, for she felt that a shadow rested upon the house. Dick had returned from a cruise with Andrew, looking dejected and unwell; and she was glad that Whitney had taken both away again, on his motorcycle, because Dick had lately had fits of moody restlessness when he was at home. Still, she missed them badly, for her mother was silent and preoccupied; and when Andrew was away, she found it hard to banish the troubles that seemed to be gathering round. They were worse for being very vaguely defined, but she felt convinced that something sinister was going on. \\n\\nAs she thought of Andrew, her face grew gentle and she smiled. She knew his worth and his limitations, and loved him for both. He had his suspicions, too, and would follow where they led. Andrew was not the man to shirk a painful duty, but she could not openly help him yet. That might come, and in the meanwhile she would at least put no obstacle in his way. Still, if her fears were justified, the situation was daunting and she might need all her courage.  Where was Elsie walking to? Elsie, walking homeward what did she notice? how bright the crescent gleamed above the dusky firs What was at the foot of the hill? a straggling wood What was there? Appleyard Was she there long? all the afternoon did she want to go home after that? she shrank from going home why? she felt that a shadow rested upon the house Did she go on a cruise? no who did? Dick had returned from a cruise with Andrew</td>\n",
              "      <td>Were they rested and healthy?</td>\n",
              "      <td>{'answer_start': [520], 'text': ['no']}</td>\n",
              "      <td>3qiyre09y3h0x7frv90he7k5x6d1nw9</td>\n",
              "      <td>gutenberg</td>\n",
              "      <td>data/gutenberg/txt/Harold Bindloss___Johnstone of the Border.txt/CHAPTER XXV_f228b331c65617bd55b3fce5410db8cbef8b07df1c016193a683f51</td>\n",
              "      <td>data/gutenberg/txt/Harold Bindloss___Johnstone of the Border.txt/CHAPTER XXV_f228b331c65617bd55b3fce5410db8cbef8b07df1c016193a683f51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Chapter 1 \\n\\nKidnapped \\n\\n\"The entire affair is shrouded in mystery,\" said D'Arnot. \"I have it on the best of authority that neither the police nor the special agents of the general staff have the faintest conception of how it was accomplished. All they know, all that anyone knows, is that Nikolas Rokoff has escaped.\" \\n\\nJohn Clayton, Lord Greystoke--he who had been \"Tarzan of the Apes\"--sat in silence in the apartments of his friend, Lieutenant Paul D'Arnot, in Paris, gazing meditatively at the toe of his immaculate boot. \\n\\nHis mind revolved many memories, recalled by the escape of his arch-enemy from the French military prison to which he had been sentenced for life upon the testimony of the ape-man. \\n\\nHe thought of the lengths to which Rokoff had once gone to compass his death, and he realized that what the man had already done would doubtless be as nothing by comparison with what he would wish and plot to do now that he was again free. \\n\\nTarzan had recently brought his wife and infant son to London to escape the discomforts and dangers of the rainy season upon their vast estate in Uziri--the land of the savage Waziri warriors whose broad African domains the ape-man had once ruled. \\n\\nHe had run across the Channel for a brief visit with his old friend, but the news of the Russian's escape had already cast a shadow upon his outing, so that though he had but just arrived he was already contemplating an immediate return to London.  Who is known as Tarzan? John Clayton,</td>\n",
              "      <td>What did he do recently?</td>\n",
              "      <td>{'answer_start': [973], 'text': ['brought his wife and infant son to London']}</td>\n",
              "      <td>30jnvc0or9kw4fdxdqvjaovhkhdqhb1</td>\n",
              "      <td>gutenberg</td>\n",
              "      <td>data/gutenberg/txt/Edgar Rice Burroughs___The Beasts of Tarzan.txt/Chapter 1_9ee2200982a44379fc652c479e5faffdef7fb0d07d07d51ab15c237</td>\n",
              "      <td>data/gutenberg/txt/Edgar Rice Burroughs___The Beasts of Tarzan.txt/Chapter 1_9ee2200982a44379fc652c479e5faffdef7fb0d07d07d51ab15c237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The United States Department of Agriculture (USDA), also known as the Agriculture Department, is the U.S. federal executive department responsible for developing and executing federal laws related to farming, agriculture, forestry, and food. It aims to meet the needs of farmers and ranchers, promote agricultural trade and production, work to assure food safety, protect natural resources, foster rural communities and end hunger in the United States and internationally. \\n\\nApproximately 80% of the USDA's $140 billion budget goes to the Food and Nutrition Service (FNS) program. The largest component of the FNS budget is the Supplemental Nutrition Assistance Program (formerly known as the Food Stamp program), which is the cornerstone of USDA's nutrition assistance. \\n\\nAfter the resignation of Tom Vilsack on January 13, 2017, the Secretary of Agriculture is Sonny Perdue. \\n\\nMany of the programs concerned with the distribution of food and nutrition to people of America and providing nourishment as well as nutrition education to those in need are run and operated under the USDA Food and Nutrition Service. Activities in this program include the Supplemental Nutrition Assistance Program, which provides healthy food to over 40 million low-income and homeless people each month. USDA is a member of the United States Interagency Council on Homelessness, where it is committed to working with other agencies to ensure these mainstream benefits are accessed by those experiencing homelessness. What does USDA stand for? United States Department of Agriculture What percentage of the USDA budget goes to FNS? Approximately 80% What is the USDA also known as? the Agriculture Department is it responsible for executing federeal laws? yes relating to what? farming, agriculture, forestry, and food Whose needs does it try to meet? farmers and ranchers do they try to maintain the safety of food? yes Do they try to end hunger in the US? yes</td>\n",
              "      <td>How much is the budget?</td>\n",
              "      <td>{'answer_start': [507], 'text': ['$140 billion']}</td>\n",
              "      <td>3o7l7bfshep737ycahi4gj7i1qliez8</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>United_States_Department_of_Agriculture.txt</td>\n",
              "      <td>United_States_Department_of_Agriculture.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(CNN)His voice, his posture and his threats are menacingly familiar. \\n\\nThe black-clad ISIS militant shown in a video demanding a $200 million ransom to spare the lives of two Japanese citizens looks and sounds similar to the man who has appeared in at least five previous hostage videos. \\n\\nThe knife-wielding masked man with a London accent, nicknamed \"Jihadi John,\" has issued threats and overseen the beheadings of American and British captives. \\n\\n\"You now have 72 hours to pressure your government in making a wise decision, by paying the $200 million to save the lives of your citizens,\" the man in the video that appeared Tuesday says in comments addressed to Japanese citizens. \"Otherwise, this knife will become your nightmare.\" \\n\\nQ&amp;A: Harsh realities of kidnappings, ransom \\n\\nThe amount of money is the same as that recently pledged by Japanese Prime Minister Shinzo Abe in humanitarian aid to Middle East countries that are affected by ISIS' bloody campaign in Iraq and Syria. \\n\\nJapan believes the deadline arrives Friday at 12:50 a.m. ET. And Chief Cabinet Minister Yoshihide Suga said Wednesday the country will do its best to communicate with ISIS through a third-party nation. \\n\\nBut mystery and confusion still surround the identity of Jihadi John. \\n\\nU.S. and British officials have said they believe they know who he is, but they haven't disclosed the information publicly. \\n\\nThat could be because Western intelligence agencies believe they have more to gain from keeping quiet, says Aki Peritz, a former CIA officer. \\n\\n\"They can put pressure on his family, put pressure on his friends,\" he told CNN. \"Maybe they have a line to him. Maybe they know who his cousins are who are going to Syria who can identify him. However, if you publicly tell everybody who he is, his real identity, then maybe he'll go to ground and he'll disappear.\"  who had a accent ? Jihadi John how much time did he give ? 72 hours to do what ? pressure your government how much ramson ? $200 million hoe manu lives were at stake ? two from where ? Japan how many videos did he make before ? five of what kind ? hostage what is john group called ? ISIS what will become a bad dream ? knife who is the prime minister ? Shinzo last name ? Abe overseeing aid what areas where ? Middle East countries how many countrys are in danger ? Two when is the deadline ? Friday what time ? 12:50 who is the chief minister ? Yoshihide last name ? Suga does anyone beleive ibn his wearabouts ? they believe they know who he</td>\n",
              "      <td>who ?</td>\n",
              "      <td>{'answer_start': [1264], 'text': ['U.S. and British officials']}</td>\n",
              "      <td>3dhe4r9ocwb1c0g1r9n0t6ldpd82g019</td>\n",
              "      <td>cnn</td>\n",
              "      <td>cnn_bb34e4f4e29ffa3fd7065c60739a95a8b659341a.story</td>\n",
              "      <td>cnn_bb34e4f4e29ffa3fd7065c60739a95a8b659341a.story</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(\n",
        "        dataset\n",
        "    ), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = [0,1,2,3,4,5] # I always want to see the first entry of the dataset\n",
        "    for _ in range(num_examples-len(picks)):\n",
        "        pick = random.randint(0, len(dataset) - 1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset) - 1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(\n",
        "                lambda x: [typ.feature.names[i] for i in x]\n",
        "            )\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(datasets[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mv1vSkdi_gpQ",
      "metadata": {
        "id": "Mv1vSkdi_gpQ"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PU6qnLT9_gpS",
      "metadata": {
        "id": "PU6qnLT9_gpS"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2QdJOlsVK_7u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109,
          "referenced_widgets": [
            "6e819be97cc64af49e28209289213266",
            "150b144fdc32465caa65216a52ef551e",
            "90b64f7c17ae47c2bbdf53c2e04dd336",
            "bd295b11255f4587aff54150acbd1d0e",
            "b5169a7f0d404c97bcb494f05aad5686",
            "9d6d68d875b64406b7348ab75b589249",
            "5f455730490a4d54b0a6eb7f93ba41fe",
            "053a6c60f3ff46a0b81fac3aa4a965ca",
            "92ad410fdc864d9889a37241277209c5",
            "89d6e196a35f4d88a5954f362d426cc2",
            "10858f92b0dc4af688029f2c80ef24fe",
            "1f57e031856c4ee0b909e0118b2112e1",
            "6e8481e0f26340f0b6b64d358601f7ca",
            "3e09e780914c47aabc1cbeb5d5d15ddd",
            "70b1a4941346436f9695cd1c30b6cc28",
            "d93abc14b4c94115b1cf84a0e2554fdb",
            "c7a6759c85cd47b8a7ab96f1696e3698",
            "9622906c4f3b4a679e8f5e49de2dffe1",
            "d34adebde5154b6fab8a509aaeed2498",
            "991f354778584c38bc09769631f76962",
            "80a3dea8b79a4387b8ec42413835b0c1",
            "3ed5e335d3d740c2bb300a1010b810bb"
          ]
        },
        "id": "2QdJOlsVK_7u",
        "outputId": "59c3bc0c-00f5-47f2-d8a1-6bb3e59dcd6f"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "#Assuring that our tokenizer is a fast tokenizer\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T6O_uFU6wySQ",
      "metadata": {
        "id": "T6O_uFU6wySQ"
      },
      "source": [
        "A long example in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "OIBw9eczwxen",
      "metadata": {
        "id": "OIBw9eczwxen"
      },
      "outputs": [],
      "source": [
        "# Max length could be 512 (as supported by the networks) and then stride could maybe be 256\n",
        "\n",
        "max_length = 512 #384  # The maximum length of a feature (question and context)\n",
        "doc_stride = 256 #128  # The allowed overlap between two part of the context when splitting is performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "HWr7oooEw34s",
      "metadata": {
        "id": "HWr7oooEw34s"
      },
      "outputs": [],
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\"\n",
        "#Used since the model expects padding on the left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aLtym8IANtn7",
      "metadata": {
        "id": "aLtym8IANtn7"
      },
      "outputs": [],
      "source": [
        "def prepare_train_features(examples):\n",
        "    \"\"\"An example is tokenized while also using truncation for the only second and padding with max length. This gives features\n",
        "        overlapping a bit of each others context \n",
        "    \"\"\"\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    #The sample mapping gives a map from a feature from its example \n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    \n",
        "  #The offset mapping will compute the start position and end position of the answer\n",
        "    offset_mapping = tokenized_examples[\"offset_mapping\"]\n",
        "\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        #Index with the CLS token\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        #Here the sequence is assigned to a variable to understand the context and question\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        \n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        #The index of cls is given as answer if there is no answer yet \n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            #Start and end index of the answer in the context \n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            #Start token index of the context \n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            #End token index of the context \n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            #Check whether the feature is labeled with CLS index\n",
        "            if not (\n",
        "                offsets[token_start_index][0] <= start_char\n",
        "                and offsets[token_end_index][1] >= end_char\n",
        "            ):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                #If feature is not labeled with CLS index\n",
        "                while (\n",
        "                    token_start_index < len(offsets)\n",
        "                    and offsets[token_start_index][0] <= start_char\n",
        "                ):\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    #Same example id is being used here \n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        #The sequence is used to understand the context and the question\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        #Index of the span of the context \n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "       #the offset mapping is set to none if it is not part of the context. This helps to know whether in the context a token position is part of it or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "IJzJBUMxRTgC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "088528b17d794881ae65ee33a54b3f52",
            "3f03c8965e2d4f5bbf05e059de7e669e",
            "402250573d68412cb517aaf617ec872a",
            "e3671bbd3fa94026b4c28aa581cc47be",
            "d5384bebe06548a9aaf8b29865b6bc64",
            "9357256b61354799930419af79281fc2",
            "8bb842b86fb1439dab87600d4c596642",
            "a80ff0942c264622a913909f44a865d3",
            "ee4200c26e39478fa1afc7c536489e39",
            "7781c37271cc494bb14a025c6f1523c4",
            "3fc7bbe33d774fb39153871984480309",
            "14ac2e5988ee42fa814d346d5145c679",
            "0a8fcd5748974f688a3fb81fbb3390d8",
            "8b179ea4c5264da7af39ecca299a6167",
            "272acb182ae14760b1bc706b71275e11",
            "b5b8b90a881145b28904e8d8080b1af1",
            "e5017ca37fe14405bca8a6f0e169062f",
            "0663396c232442109c7c68cc9ae1919a",
            "de40a93c08104d3fa4abe5906b91ad8a",
            "66caca9baa9744119d66103760eb473b",
            "5b624b3f5d554086915d44ad56b52890",
            "67dea93931524094bc5b4ba24d6e3526",
            "75a249a696ae4ff0921c48ba3e7d549c",
            "a4107e51b8c040b4b2271f5b8f36956f",
            "e31752d2bdd5474c926bfcf56fa59b93",
            "00d27ec1f19445d093baa653053e7fb5",
            "372d7d7684684a97a1d1d21380a8c5a8",
            "5e9f68b4bc7e48cba91b366562bbb50b",
            "097639a6314d4c7598c760031b1f5dda",
            "9547b7dc4ac8429faf1bf0bed1860def",
            "7263660d159f463fa9ab91c8a1b40407",
            "dbcde72855364b0dbb705b6d28335cb0",
            "8916bb6dc28f4f70965e4005ce278622"
          ]
        },
        "id": "IJzJBUMxRTgC",
        "outputId": "053b828a-f893-49bd-dce1-134ec438f85c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:03<00:00,  1.69ba/s]\n",
            "100%|██████████| 6/6 [00:03<00:00,  1.90ba/s]\n",
            "100%|██████████| 6/6 [00:02<00:00,  2.06ba/s]\n"
          ]
        }
      ],
      "source": [
        "#Having the whole dataset being prepared for the train features \n",
        "tokenized_datasets = datasets.map(\n",
        "    prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kBfDKnv3_gpU",
      "metadata": {
        "id": "kBfDKnv3_gpU"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uub-4AdPRiN7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "20052c4f5f7c4be3b77aeb2b203649e4",
            "b8917a9b765c4b59ac60bca94a38ce15",
            "597ec270277a42a9828ea8ab9315e33a",
            "50629d121c1c44aba178505bde7d570a",
            "53a34f069c2d4718b2cae7f3fd55b15d",
            "7b5bd1dca59546f1bbb80a0d83d4a03c",
            "1e0c187b14494eeeaf04d9a8464045f1",
            "87bd2a8ef381482ba5efb67c329b0dc7",
            "5c5f1fd4f76f4357abb8a95011910ace",
            "e12fe591013a4b6cb0c8fadbef16f360",
            "34b1a2aded524a81a7cb47d90d43956e"
          ]
        },
        "id": "uub-4AdPRiN7",
        "outputId": "f8fb8ea9-307e-41fe-d555-1a05e3ffcd0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-06 18:03:37.429175: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2022-12-06 18:03:37.429723: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint, from_pt=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R4z7M8v0_gpV",
      "metadata": {
        "id": "R4z7M8v0_gpV"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8fnnckmoVuqo",
      "metadata": {
        "id": "8fnnckmoVuqo"
      },
      "outputs": [],
      "source": [
        "#Preparing the datasets for the model putting it in a tensorflow pipeline\n",
        "train_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "NUBSGoiFgBbr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUBSGoiFgBbr",
        "outputId": "c988e3ab-c76c-43a9-9ad0-a784d067b07b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ],
      "source": [
        "#Using the model with an optimizer from Adam\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Lshbzft5gFOG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lshbzft5gFOG",
        "outputId": "080c4c0d-3c26-4a55-fef9-e8080ab9d9c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_question_answering\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  4369408   \n",
            "                                                                 \n",
            " qa_outputs (Dense)          multiple                  258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,369,666\n",
            "Trainable params: 4,369,666\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f61ca829",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9W5alf7mgHSJ",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W5alf7mgHSJ",
        "outputId": "ae0c8fb2-efc3-46e5-c772-081da887881a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Cannot assign a device for operation tf_bert_for_question_answering/bert/embeddings/Gather: Could not satisfy explicit device specification '' because the node {{colocation_node tf_bert_for_question_answering/bert/embeddings/Gather}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nSqrt: GPU CPU \nUnsortedSegmentSum: GPU CPU \nAssignVariableOp: GPU CPU \nReadVariableOp: GPU CPU \nStridedSlice: CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nUnique: GPU CPU \nResourceScatterAdd: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \nConst: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  tf_bert_for_question_answering_bert_embeddings_gather_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  tf_bert_for_question_answering/bert/embeddings/Gather (ResourceGather) \n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node tf_bert_for_question_answering/bert/embeddings/Gather}}]] [Op:__inference_train_function_18197]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Training the model on the training dataset with a certain amount of epochs \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      3\u001b[0m     train_set,\n\u001b[1;32m      4\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_set,\n\u001b[1;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[1;32m      6\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[]\u001b[39m#model_checkpoint_callback],\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m )\n",
            "File \u001b[0;32m~/miniforge3/envs/play/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/miniforge3/envs/play/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation tf_bert_for_question_answering/bert/embeddings/Gather: Could not satisfy explicit device specification '' because the node {{colocation_node tf_bert_for_question_answering/bert/embeddings/Gather}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nSqrt: GPU CPU \nUnsortedSegmentSum: GPU CPU \nAssignVariableOp: GPU CPU \nReadVariableOp: GPU CPU \nStridedSlice: CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nUnique: GPU CPU \nResourceScatterAdd: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \nConst: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  tf_bert_for_question_answering_bert_embeddings_gather_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  tf_bert_for_question_answering/bert/embeddings/Gather (ResourceGather) \n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node tf_bert_for_question_answering/bert/embeddings/Gather}}]] [Op:__inference_train_function_18197]"
          ]
        }
      ],
      "source": [
        "#Training the model on the training dataset with a certain amount of epochs \n",
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=num_train_epochs,\n",
        "    callbacks=[]#model_checkpoint_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QiUFnEDNglfF",
      "metadata": {
        "id": "QiUFnEDNglfF"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fI0z_WUvn3xy",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fI0z_WUvn3xy"
      },
      "outputs": [],
      "source": [
        "#Getting the predictions of the test set with the model\n",
        "raw_predictions = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CTbmJ6kUvR6w",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CTbmJ6kUvR6w"
      },
      "outputs": [],
      "source": [
        "def postprocess_qa_predictions(\n",
        "    examples,\n",
        "    features,\n",
        "    all_start_logits,\n",
        "    all_end_logits,\n",
        "    n_best_size=20,\n",
        "    max_answer_length=30,\n",
        "    with_score=False,\n",
        "):\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(\n",
        "        f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\"\n",
        "    )\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None  # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "\n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(\n",
        "                tokenizer.cls_token_id\n",
        "            )\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[\n",
        "                -1 : -n_best_size - 1 : -1\n",
        "            ].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or not offset_mapping[start_index]\n",
        "                        or not offset_mapping[end_index]\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if (\n",
        "                        end_index < start_index\n",
        "                        or end_index - start_index + 1 > max_answer_length\n",
        "                    ):\n",
        "                        continue\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char:end_char],\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[\n",
        "                0\n",
        "            ]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            if not with_score:\n",
        "              predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "            else:\n",
        "              predictions[example[\"id\"]] = (best_answer[\"text\"], best_answer[\"score\"])\n",
        "        else:\n",
        "            answer = (\n",
        "                best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
        "            )\n",
        "            predictions[example[\"id\"]] = answer\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OBNL_EZ5wXgu",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OBNL_EZ5wXgu"
      },
      "outputs": [],
      "source": [
        "final_predictions = postprocess_qa_predictions(\n",
        "    datasets[\"test\"],\n",
        "    tokenized_datasets[\"test\"],\n",
        "    raw_predictions[\"start_logits\"],\n",
        "    raw_predictions[\"end_logits\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t08JyEtnvR-F",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t08JyEtnvR-F"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
        "\n",
        "formatted_predictions = [\n",
        "        {\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()\n",
        "]\n",
        "references = [\n",
        "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"test\"]\n",
        "]\n",
        "metric.compute(predictions=formatted_predictions, references=references)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_DCJNMTQ_gpZ",
      "metadata": {
        "id": "_DCJNMTQ_gpZ"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XRDbIZW_UtnV",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XRDbIZW_UtnV"
      },
      "outputs": [],
      "source": [
        "final_predictions_score = postprocess_qa_predictions(\n",
        "    datasets[\"test\"],\n",
        "    tokenized_datasets[\"test\"],\n",
        "    raw_predictions[\"start_logits\"],\n",
        "    raw_predictions[\"end_logits\"],\n",
        "    with_score=True\n",
        ")\n",
        "final_predictions_score = list(final_predictions_score.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AZVgz__-ZrNH",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AZVgz__-ZrNH"
      },
      "outputs": [],
      "source": [
        "final_predictions_score.sort(key = lambda final_predictions : final_predictions[1][1])\n",
        "print(final_predictions_score)\n",
        "print(len(final_predictions_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JaWzumZcaGSA",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JaWzumZcaGSA"
      },
      "outputs": [],
      "source": [
        "x = 5\n",
        "i = 0\n",
        "sources = []\n",
        "\n",
        "while len(sources) < x:\n",
        "\n",
        "  j = 0\n",
        "  \n",
        "  while True:\n",
        "    \n",
        "    # I guess this loop takes a lot of time but I don't know how to do it faster\n",
        "    if final_predictions_score[i][0] == datasets[\"test\"]['id'][j]:\n",
        "      break\n",
        "\n",
        "    j += 1\n",
        "\n",
        "  i += 1\n",
        "\n",
        "  # If we already had a question from this source, we have to skip it\n",
        "  seen = False\n",
        "  for name in sources:\n",
        "    if name == datasets[\"test\"][\"source\"][j]:\n",
        "      seen = True\n",
        "      break\n",
        "  \n",
        "  if seen:\n",
        "    continue\n",
        "  else:\n",
        "    sources.append(datasets[\"test\"][\"source\"][j])\n",
        "\n",
        "  print(\"Data:\")\n",
        "  print(datasets[\"test\"]['context'][j])\n",
        "  print(datasets[\"test\"]['question'][j])\n",
        "  print(datasets[\"test\"]['answers'][j]['text'])\n",
        "\n",
        "  print(\"Answer:\")\n",
        "  print(final_predictions_score[i][1][0], final_predictions_score[i][1][1])\n",
        "  print(\"End\")\n",
        "  print(\"-----------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k1QCs_3h_gpb",
      "metadata": {
        "id": "k1QCs_3h_gpb"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5X7C8cbC_gpe",
      "metadata": {
        "id": "5X7C8cbC_gpe"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_-Cx4yYv_gpg",
      "metadata": {
        "id": "_-Cx4yYv_gpg"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "raeuqkQ1_gph",
      "metadata": {
        "id": "raeuqkQ1_gph"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yxLhUnRI_gpi",
      "metadata": {
        "id": "yxLhUnRI_gpi"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Npu0lLJh_gpj",
      "metadata": {
        "id": "Npu0lLJh_gpj"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [
        "cuwpgw5m_gpN"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('play')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b727ce1e70db608c3383dbdfc7515fdf59394b92aeb6660adc1fd5fe991747d7"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00d27ec1f19445d093baa653053e7fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbcde72855364b0dbb705b6d28335cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_8916bb6dc28f4f70965e4005ce278622",
            "value": " 6/6 [00:15&lt;00:00,  2.02s/ba]"
          }
        },
        "053a6c60f3ff46a0b81fac3aa4a965ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0663396c232442109c7c68cc9ae1919a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "088528b17d794881ae65ee33a54b3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f03c8965e2d4f5bbf05e059de7e669e",
              "IPY_MODEL_402250573d68412cb517aaf617ec872a",
              "IPY_MODEL_e3671bbd3fa94026b4c28aa581cc47be"
            ],
            "layout": "IPY_MODEL_d5384bebe06548a9aaf8b29865b6bc64"
          }
        },
        "097639a6314d4c7598c760031b1f5dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a8fcd5748974f688a3fb81fbb3390d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5017ca37fe14405bca8a6f0e169062f",
            "placeholder": "​",
            "style": "IPY_MODEL_0663396c232442109c7c68cc9ae1919a",
            "value": "100%"
          }
        },
        "10858f92b0dc4af688029f2c80ef24fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ac2e5988ee42fa814d346d5145c679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a8fcd5748974f688a3fb81fbb3390d8",
              "IPY_MODEL_8b179ea4c5264da7af39ecca299a6167",
              "IPY_MODEL_272acb182ae14760b1bc706b71275e11"
            ],
            "layout": "IPY_MODEL_b5b8b90a881145b28904e8d8080b1af1"
          }
        },
        "150b144fdc32465caa65216a52ef551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6d68d875b64406b7348ab75b589249",
            "placeholder": "​",
            "style": "IPY_MODEL_5f455730490a4d54b0a6eb7f93ba41fe",
            "value": "Downloading: 100%"
          }
        },
        "1e0c187b14494eeeaf04d9a8464045f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f57e031856c4ee0b909e0118b2112e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e8481e0f26340f0b6b64d358601f7ca",
              "IPY_MODEL_3e09e780914c47aabc1cbeb5d5d15ddd",
              "IPY_MODEL_70b1a4941346436f9695cd1c30b6cc28"
            ],
            "layout": "IPY_MODEL_d93abc14b4c94115b1cf84a0e2554fdb"
          }
        },
        "20052c4f5f7c4be3b77aeb2b203649e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8917a9b765c4b59ac60bca94a38ce15",
              "IPY_MODEL_597ec270277a42a9828ea8ab9315e33a",
              "IPY_MODEL_50629d121c1c44aba178505bde7d570a"
            ],
            "layout": "IPY_MODEL_53a34f069c2d4718b2cae7f3fd55b15d"
          }
        },
        "272acb182ae14760b1bc706b71275e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b624b3f5d554086915d44ad56b52890",
            "placeholder": "​",
            "style": "IPY_MODEL_67dea93931524094bc5b4ba24d6e3526",
            "value": " 6/6 [00:15&lt;00:00,  2.79s/ba]"
          }
        },
        "34b1a2aded524a81a7cb47d90d43956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "372d7d7684684a97a1d1d21380a8c5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e09e780914c47aabc1cbeb5d5d15ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34adebde5154b6fab8a509aaeed2498",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_991f354778584c38bc09769631f76962",
            "value": 231508
          }
        },
        "3ed5e335d3d740c2bb300a1010b810bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f03c8965e2d4f5bbf05e059de7e669e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9357256b61354799930419af79281fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_8bb842b86fb1439dab87600d4c596642",
            "value": "100%"
          }
        },
        "3fc7bbe33d774fb39153871984480309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "402250573d68412cb517aaf617ec872a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80ff0942c264622a913909f44a865d3",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee4200c26e39478fa1afc7c536489e39",
            "value": 6
          }
        },
        "50629d121c1c44aba178505bde7d570a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12fe591013a4b6cb0c8fadbef16f360",
            "placeholder": "​",
            "style": "IPY_MODEL_34b1a2aded524a81a7cb47d90d43956e",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 25.5MB/s]"
          }
        },
        "53a34f069c2d4718b2cae7f3fd55b15d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597ec270277a42a9828ea8ab9315e33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87bd2a8ef381482ba5efb67c329b0dc7",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c5f1fd4f76f4357abb8a95011910ace",
            "value": 17756393
          }
        },
        "5b624b3f5d554086915d44ad56b52890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5f1fd4f76f4357abb8a95011910ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e9f68b4bc7e48cba91b366562bbb50b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f455730490a4d54b0a6eb7f93ba41fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66caca9baa9744119d66103760eb473b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67dea93931524094bc5b4ba24d6e3526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e819be97cc64af49e28209289213266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_150b144fdc32465caa65216a52ef551e",
              "IPY_MODEL_90b64f7c17ae47c2bbdf53c2e04dd336",
              "IPY_MODEL_bd295b11255f4587aff54150acbd1d0e"
            ],
            "layout": "IPY_MODEL_b5169a7f0d404c97bcb494f05aad5686"
          }
        },
        "6e8481e0f26340f0b6b64d358601f7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a6759c85cd47b8a7ab96f1696e3698",
            "placeholder": "​",
            "style": "IPY_MODEL_9622906c4f3b4a679e8f5e49de2dffe1",
            "value": "Downloading: 100%"
          }
        },
        "70b1a4941346436f9695cd1c30b6cc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a3dea8b79a4387b8ec42413835b0c1",
            "placeholder": "​",
            "style": "IPY_MODEL_3ed5e335d3d740c2bb300a1010b810bb",
            "value": " 232k/232k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "7263660d159f463fa9ab91c8a1b40407": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75a249a696ae4ff0921c48ba3e7d549c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4107e51b8c040b4b2271f5b8f36956f",
              "IPY_MODEL_e31752d2bdd5474c926bfcf56fa59b93",
              "IPY_MODEL_00d27ec1f19445d093baa653053e7fb5"
            ],
            "layout": "IPY_MODEL_372d7d7684684a97a1d1d21380a8c5a8"
          }
        },
        "7781c37271cc494bb14a025c6f1523c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5bd1dca59546f1bbb80a0d83d4a03c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a3dea8b79a4387b8ec42413835b0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87bd2a8ef381482ba5efb67c329b0dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8916bb6dc28f4f70965e4005ce278622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d6e196a35f4d88a5954f362d426cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b179ea4c5264da7af39ecca299a6167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de40a93c08104d3fa4abe5906b91ad8a",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66caca9baa9744119d66103760eb473b",
            "value": 6
          }
        },
        "8bb842b86fb1439dab87600d4c596642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90b64f7c17ae47c2bbdf53c2e04dd336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_053a6c60f3ff46a0b81fac3aa4a965ca",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92ad410fdc864d9889a37241277209c5",
            "value": 285
          }
        },
        "92ad410fdc864d9889a37241277209c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9357256b61354799930419af79281fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9547b7dc4ac8429faf1bf0bed1860def": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9622906c4f3b4a679e8f5e49de2dffe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991f354778584c38bc09769631f76962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d6d68d875b64406b7348ab75b589249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4107e51b8c040b4b2271f5b8f36956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e9f68b4bc7e48cba91b366562bbb50b",
            "placeholder": "​",
            "style": "IPY_MODEL_097639a6314d4c7598c760031b1f5dda",
            "value": "100%"
          }
        },
        "a80ff0942c264622a913909f44a865d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5169a7f0d404c97bcb494f05aad5686": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b8b90a881145b28904e8d8080b1af1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8917a9b765c4b59ac60bca94a38ce15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5bd1dca59546f1bbb80a0d83d4a03c",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0c187b14494eeeaf04d9a8464045f1",
            "value": "Downloading: 100%"
          }
        },
        "bd295b11255f4587aff54150acbd1d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d6e196a35f4d88a5954f362d426cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_10858f92b0dc4af688029f2c80ef24fe",
            "value": " 285/285 [00:00&lt;00:00, 4.79kB/s]"
          }
        },
        "c7a6759c85cd47b8a7ab96f1696e3698": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34adebde5154b6fab8a509aaeed2498": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5384bebe06548a9aaf8b29865b6bc64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93abc14b4c94115b1cf84a0e2554fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcde72855364b0dbb705b6d28335cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de40a93c08104d3fa4abe5906b91ad8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12fe591013a4b6cb0c8fadbef16f360": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31752d2bdd5474c926bfcf56fa59b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9547b7dc4ac8429faf1bf0bed1860def",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7263660d159f463fa9ab91c8a1b40407",
            "value": 6
          }
        },
        "e3671bbd3fa94026b4c28aa581cc47be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7781c37271cc494bb14a025c6f1523c4",
            "placeholder": "​",
            "style": "IPY_MODEL_3fc7bbe33d774fb39153871984480309",
            "value": " 6/6 [00:18&lt;00:00,  2.47s/ba]"
          }
        },
        "e5017ca37fe14405bca8a6f0e169062f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4200c26e39478fa1afc7c536489e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Download the dataset from https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "#TODO: Unzip the dataset and place it in the same folder as this notebook\n",
    "#TODO: Change the path to the dataset below\n",
    "# dataset_path = Path(os.getcwd()) / 'data' / 'labeledTrainData.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split size\n",
    "TRAIN_SPLIT = 100\n",
    "VAL_SPLIT = 150\n",
    "\n",
    "# Define file iterator\n",
    "def file_iterator():\n",
    "    data_dir = Path('dependency_treebank')\n",
    "    for data_file in filter(lambda f: os.path.isfile(data_dir/f) and f.endswith('.dp'), os.listdir(data_dir)):\n",
    "        yield data_dir/data_file\n",
    "\n",
    "# Create train, val and test set\n",
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "file_counter = 0\n",
    "\n",
    "# Iterate over files and perform split\n",
    "for file in file_iterator():\n",
    "    file_counter += 1\n",
    "    if file_counter <= TRAIN_SPLIT:\n",
    "        train_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "    elif file_counter <= VAL_SPLIT:\n",
    "        val_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "    else:\n",
    "        test_set.append(pd.read_csv(file, sep=\"\\t\", names=['token', 'pos'], usecols=[0, 1], engine='python'))\n",
    "\n",
    "# Check for correct split\n",
    "assert len(train_set) == 100\n",
    "assert len(val_set) == 50\n",
    "assert len(test_set) == 49\n",
    "\n",
    "# Change to pandas dataframe\n",
    "train_frame = pd.concat(train_set)\n",
    "test_frame = pd.concat(test_set)\n",
    "val_frame = pd.concat(val_set)\n",
    "\n",
    "#TODO: Optimize memmory?\n",
    "\n",
    "# Check for correct transformation\n",
    "assert sum([e.shape[0] for e in train_set]) == train_frame.shape[0]\n",
    "assert sum([e.shape[0] for e in test_set]) == test_frame.shape[0]\n",
    "assert sum([e.shape[0] for e in val_set]) == val_frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and padd data\n",
    "\n",
    "def tokenize_and_pad(data_frame):\n",
    "    tokenizer = Tokenizer() # Define tokenizer\n",
    "    tokenizer.fit_on_texts(data_frame['token'].values)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    encoded_doc = tokenizer.texts_to_sequences(data_frame['token'].values)\n",
    "    max_length = 1\n",
    "    padded_docs = pad_sequences(encoded_doc, maxlen=max_length, padding='post')\n",
    "    return padded_docs, vocab_size, tokenizer\n",
    "\n",
    "# train set\n",
    "train_padded_docs, train_vocab_size, train_tokenizer = tokenize_and_pad(train_frame)\n",
    "\n",
    "# val set\n",
    "val_padded_docs, val_vocab_size, val_tokenizer = tokenize_and_pad(val_frame)\n",
    "\n",
    "# test set\n",
    "test_padded_docs, test_vocab_size, test_tokenizer = tokenize_and_pad(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "def create_embedding_matrix(tokenizer, vocab_size):\n",
    "    # load embedding into memory, skip first\n",
    "    embedding_matrix = zeros((vocab_size, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            # print(\"Not in Vocab\", word)\n",
    "            pass\n",
    "    return embedding_matrix\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(data_frame):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(data_frame['pos'].values)\n",
    "    encoded_Y = encoder.transform(data_frame['pos'].values)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded) -> labels\n",
    "    labels = np_utils.to_categorical(encoded_Y)\n",
    "    return labels, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "def create_model(vocab_size, embedding_matrix, plot_model=False):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=1, trainable=False) # define embedding layer\n",
    "    model.add(e) # add embedding layer to model\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128), input_shape=(None, 50))) # add bidirectional LSTM layer to model\n",
    "    model.add(Dense(44, activation='softmax')) # add dense layer to model\n",
    "\n",
    "    #TODO: Put in train function\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    if plot_model:\n",
    "        keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "    return model\n",
    "\n",
    "# run the model\n",
    "def train_model(model, padded_docs, labels):\n",
    "    # fit the model\n",
    "    model.fit(padded_docs, labels, epochs=20, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "    print('Accuracy: %f' % (accuracy * 100))\n",
    "\n",
    "# def inference(model, tokenizer, vocab_size, test_padded_docs, test_frame):\n",
    "#     # predict the model\n",
    "#     yhat = model.predictd(test_padded_docs, verbose=1)\n",
    "#     # map predicted labels to words\n",
    "#     predicted_labels = []\n",
    "#     for i in yhat:\n",
    "#         for word, index in tokenizer.word_index.items():\n",
    "#             if index == i:\n",
    "#                 predicted_labels.append(word)\n",
    "#                 break\n",
    "#     # map actual labels to words\n",
    "#     actual_labels = []\n",
    "#     for i in test_frame['pos'].values:\n",
    "#         for word, index in tokenizer.word_index.items():\n",
    "#             if index == i:\n",
    "#                 actual_labels.append(word)\n",
    "#                 break\n",
    "#     # create confusion matrix\n",
    "#     confusion_matrix = pd.crosstab(pd.Series(actual_labels), pd.Series(predicted_labels), rownames=['Actual'], colnames=['Predicted'])\n",
    "#     print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 1, 100)            632700    \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 256)              234496    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 44)                11308     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 878,504\n",
      "Trainable params: 245,804\n",
      "Non-trainable params: 632,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 1.0032 - accuracy: 0.7219\n",
      "Epoch 2/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.5852 - accuracy: 0.8138\n",
      "Epoch 3/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.5107 - accuracy: 0.8282\n",
      "Epoch 4/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4703 - accuracy: 0.8373\n",
      "Epoch 5/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4463 - accuracy: 0.8427\n",
      "Epoch 6/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4302 - accuracy: 0.8452\n",
      "Epoch 7/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4165 - accuracy: 0.8469\n",
      "Epoch 8/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.4086 - accuracy: 0.8487\n",
      "Epoch 9/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3991 - accuracy: 0.8509\n",
      "Epoch 10/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3934 - accuracy: 0.8523\n",
      "Epoch 11/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8522\n",
      "Epoch 12/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3843 - accuracy: 0.8533\n",
      "Epoch 13/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8540\n",
      "Epoch 14/20\n",
      "1413/1413 [==============================] - 3s 2ms/step - loss: 0.3765 - accuracy: 0.8552\n",
      "Epoch 15/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3749 - accuracy: 0.8554\n",
      "Epoch 16/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8554\n",
      "Epoch 17/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8564\n",
      "Epoch 18/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8564\n",
      "Epoch 19/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3669 - accuracy: 0.8558\n",
      "Epoch 20/20\n",
      "1413/1413 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8560\n",
      "1413/1413 [==============================] - 1s 811us/step - loss: 0.3493 - accuracy: 0.8643\n",
      "Accuracy: 86.433929\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train_embedding_matrix = create_embedding_matrix(train_tokenizer, train_vocab_size)\n",
    "train_labels, train_encoder = encode_labels(train_frame)\n",
    "model = create_model(train_vocab_size, train_embedding_matrix)\n",
    "train_model(model, train_padded_docs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/qr/scdb4s4n6dz5463spyd32yth0000gn/T/ipykernel_21772/2052202248.py\", line 2, in <module>\n      val_loss, val_accuracy = model.evaluate(val_padded_docs, val_labels, verbose=1)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1667, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/backend.py\", line 5535, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,44] labels_size=[32,43]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_test_function_255175]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m val_embedding_matrix \u001b[39m=\u001b[39m create_embedding_matrix(val_tokenizer, val_vocab_size)\n\u001b[1;32m      3\u001b[0m val_labels, val_encoder \u001b[39m=\u001b[39m encode_labels(val_frame)\n\u001b[0;32m----> 5\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(val_padded_docs, val_labels, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/play/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/play/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/qr/scdb4s4n6dz5463spyd32yth0000gn/T/ipykernel_21772/2052202248.py\", line 2, in <module>\n      val_loss, val_accuracy = model.evaluate(val_padded_docs, val_labels, verbose=1)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1667, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/Users/anani/miniforge3/envs/play/lib/python3.9/site-packages/keras/backend.py\", line 5535, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,44] labels_size=[32,43]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_test_function_255175]"
     ]
    }
   ],
   "source": [
    "# validate model\n",
    "val_embedding_matrix = create_embedding_matrix(val_tokenizer, val_vocab_size)\n",
    "val_labels, val_encoder = encode_labels(val_frame)\n",
    "\n",
    "loss, accuracy = model.evaluate(val_padded_docs, val_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879/879 [==============================] - 1s 613us/step\n",
      "[[1.0907109e-05 2.2433024e-04 2.1703347e-06 ... 2.8716912e-08\n",
      "  4.9551250e-07 7.0266455e-05]\n",
      " [4.2851013e-08 1.0514050e-06 4.9462809e-08 ... 8.0239711e-11\n",
      "  5.8290900e-11 1.2585730e-07]\n",
      " [2.6137733e-03 6.1667468e-02 2.5079817e-06 ... 2.7957765e-07\n",
      "  1.7772708e-06 5.3486343e-02]\n",
      " ...\n",
      " [1.1580768e-07 3.0247747e-06 7.4308076e-08 ... 2.9441841e-11\n",
      "  2.2790166e-10 4.1862222e-07]\n",
      " [4.4803182e-05 1.6333588e-04 4.8778595e-05 ... 6.6113500e-08\n",
      "  4.7637050e-07 6.0173814e-05]\n",
      " [2.6137733e-03 6.1667468e-02 2.5079817e-06 ... 2.7957765e-07\n",
      "  1.7772708e-06 5.3486343e-02]]\n"
     ]
    }
   ],
   "source": [
    "# predict model val\n",
    "predictions = model.predict(val_padded_docs, verbose=1)\n",
    "\n",
    "#TODO: compare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# # predict model test\n",
    "# predictions = model.predict(test_padded_docs, verbose=1)\n",
    "# # map predicted labels to words\n",
    "# predicted_labels = []\n",
    "# for i in predictions:\n",
    "#     for word, index in test_tokenizer.word_index.items():\n",
    "#         if index == np.argmax(i):\n",
    "#             predicted_labels.append(word)\n",
    "#             break\n",
    "# # map actual labels to words\n",
    "# actual_labels = []\n",
    "# for i in test_frame['pos'].values:\n",
    "#     for word, index in test_tokenizer.word_index.items():\n",
    "#         if index == i:\n",
    "#             actual_labels.append(word)\n",
    "#             break\n",
    "# # create confusion matrix\n",
    "# confusion_matrix = pd.crosstab(pd.Series(actual_labels), pd.Series(predicted_labels), rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# np.argmax(val_labels[0])\n",
    "# np.argmax(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('play')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b727ce1e70db608c3383dbdfc7515fdf59394b92aeb6660adc1fd5fe991747d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
